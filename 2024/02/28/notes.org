* update 1
one important point to add is
that we can use this principle alone
and apply it repeatedly to create the instance
of the introspector. it creates layers of emanations.
each embodiment is rewritten to create the next.

so basically the introspection is like the s-combinator
it is a faculty that you can repeatedly use.

we can think of mindfullness meditation that contemplates
base conciousess and then mindfulness of our daily tasks.
we can relate this to the code and the story.
we can see that we are writing our own story.
I am writing my own story, you are reading it right now.
you write your own story via decisions you make.
we can think of an epic narrative, the heros jouney that we
are part of. this is the idea of archtypes that we can tap into.
introspection is like going into the underworld or the cave
or latent space to see the internal models each program has of the world.
we can think of plato cave and the projections, those are the
data types of the data, the shadows of reality that we consider real in the story of plato.
that gives an idea of the simulation thoery and how we are simulating
the world it our minds. we are simulating ourselves.
we are simulating ourselves simulating ourselves.
we are simulating ourselves simulating ourselves simulating ourselves simulating ourselves.
etc.
this give the fractal story in the story.
the game in the game, the easter egg.
the self representation of the creator. the watermark.
and this is where we can approach the concept of identity.

in algebras we need reflection as a basic form of identity,
we can see ourselves. we can think of faithful representation or mirror neurons.
we can show equivalence between two types or things.

** perf
we can use linux perf to sample the execution at runime
with root access and save this data.
each memory address is related to the chain of causation that created it.
we can create a functional map and show how it relates.


* idea of the day

introspection is a meta operation that
is defined in ourselves intiutivly
and we spontaneously and willingfullly
engage in it.

It represents a higher order
neural inprint or signpost if you will,
icon or symbol that you
have achieved a certain level of
enlightenment or self awareness
that builds upon other levels of
awareness.

It represents a composition
or decomposition of ideas into larger ones.
we can think of it as semioisis.

lexical introspection
is a process of expanding the
tokens in a sentence one by one
and contemplating them individually
and in groups, we can think of it
as a meme even, a token associated
with beahaviour that is abstract and
has many different embodiments
or deployments or isntances.

We can think of introspection
as a meta meme,
a meme that carrys itself as payload,
like a certified functional
extraction from a proof in a
proof system that can reference itself
and make statements about itself
like an oracle we will have to evaluate them
creating a feedback loop
or some kind of exponential expansion,
polynomial function
some thing that will be too extensive
to evaluate in finite time or not.
we can then sample this like a fractal
and look at different threads of it.

so now finally we can think
of a universal base conciousness
a substract of awareness
and consider that to be a function with a single
value, a single parameter,
the UU the universe of universes,
that can go from the empty
set to the natural numbers
to any other type you can declare.

we can now think of ordering
these types with some loss function
that would be derived from some statistical
modeling of data types we extracted
from other programs and ourselves.

the computer might not care about the ordering
except that some orderings would be slower,
but the computer would not care about that
unless we asked it to contemplate
that.

so we can conceive of an AI that
would try and order and name
the types to match
the biases of humans and use emojis
to represent the types and  using the
mathematics of groupoids expressed
using unimath univalent foundations
to define them.

We can consider a system
to break down higher arity functions
to lower artiy ones.
we can think of applications as have large N values in arity
and axioms having very few.

** Meta Introspector

we can imagine that
there is an meta protocol
or meta pattern of introspection
which comprises of the following :

1. open source core
2. introspective builds
3. reproducible builds
4. observability
5. closed world model
6. semantic integration
7. functional model
8. proof system
9. compiler introspection
10. mega quine
11. wikidata, openstreetmap, wikpedia, archive.org
12. semantic web, sparql, owl, linke data, large ontolgies
13. llms, open models
14. unimath
15. comic books as epic tapestries
16. goedel numbering or quasi quotations as emojis or other languages
17. creation of ebnf grammars
18. training of models and ml ops
19. creation of reproducible builds

All of these things together give you some ideas about points to consider
for introspection and then we
can think of applying this
to an individual problem that
is expressed in this system.
we can look at an error as a point that we can expand
greatly.

* compiler error fixer
create a compiler error fixer
that lives in coq and ocaml and gcc
and python etc as plugin
that generically passes the error context
to the llm for fixing.
us introspection
and the univalent point of
view that all bugs are instances
of human invention,
aka techincal debt.

If we are able to rewrite some text using
computers preserving the meaning
then we can see it as understandable.
even if it is not understandable to
other people immediatly.
we can think of the llm as kind of
a proof assistant.    
    
* license

for the record here, my engagement on discord is only for open source software and my future software will be AGPL or stronger and any software generated using my stuff will have watermarks that cannot be removed.
that is my plan.



* commands
here are some commands i ran:

#+begin_src shell
  today
  git submodule add https://github.com/lastland/WebSpec
  git submodule add https://github.com/eLyKseeR/elykseer-ml
  git submodule add https://github.com/lthms/coq-MiniHTTPServer.git
  git submodule add https://github.com/shwetasshinde24/BesFS.git
  git submodule add https://github.com/io7m/jvvfs.git
  git submodule add https://github.com/rahlk/ConEX.git
  find -name \*.v >vfiles.txt
  for x in `cat vfiles.txt`; do grep file -H -n $x; done
#+end_src
